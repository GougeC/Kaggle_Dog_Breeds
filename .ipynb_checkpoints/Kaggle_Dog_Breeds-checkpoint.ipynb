{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identification by Image Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to be able to identify the breed of a dog given a picture of it. The data was provided by Kaggle for their dog breed identification contest. My approach is to use a convolutional neural network to classify these images. I will train a variety of networks of my own design and additionally apply some pre-trained networks and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/connor/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#import relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Input, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import ResNet50\n",
    "from keras import Model\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id        breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07  boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97        dingo"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "labels = pd.read_csv('../data/dogs/data/labels.csv.zip',compression='zip')\n",
    "labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The images are all different dimensions so this will be the parameter to\n",
    "#resize them to be square \n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data to train the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_validation():\n",
    "    #converting breed categories to categorical booleans\n",
    "    one_hot_labels = pd.get_dummies(labels['breed']).values\n",
    "    X_raw = []\n",
    "    y_raw = []\n",
    "    #loads and processes the images into image_size by image_size by 3 tensors\n",
    "    for ind, row in enumerate(labels.values):\n",
    "        img = cv2.imread('../data/dogs/data/train/{}.jpg'.format(row[0]))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_raw.append(img)\n",
    "        y_raw.append(one_hot_labels[ind,:])\n",
    "    X = np.array(X_raw)\n",
    "    y =np.array(y_raw)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2,stratify = y, random_state=1)\n",
    "    mean_pixel = np.array([103.939, 116.779, 123.68])\n",
    "    #training_mean = np.mean(X_train,axis=0)\n",
    "    X_train = X_train - mean_pixel\n",
    "    X_validation = X_validation - mean_pixel\n",
    "    return X_train, X_validation, y_train, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7532b4d52100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#creates training and validation sets with every class represented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#in both the training and validation sets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-c8304e99aba1>\u001b[0m in \u001b[0;36mprepare_train_validation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#creates training and validation sets with every class represented\n",
    "#in both the training and validation sets.\n",
    "X_train, X_validation, y_train, y_validation = prepare_train_validation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_16_conv = VGG16(weights='imagenet',include_top = False)\n",
    "img_in = Input(shape = (image_size,image_size,3),name = 'image_input')\n",
    "outputVGG16 = vgg_16_conv(img_in)\n",
    "\n",
    "X = Flatten()(outputVGG16)\n",
    "X = Dense(4096, activation='relu',name=\"dense1\")(X)\n",
    "X = Dense(4096, activation='relu',name=\"dense2\")(X)\n",
    "X = Dense(120, activation='softmax', name=\"output\")(X)\n",
    "adapted_VGG16 = Model(input = img_in,output = X)\n",
    "\n",
    "Ad = Adam(lr = .01 , beta_1 = .9, beta_2 = .999, epsilon = 1e-08, decay =0.0)\n",
    "adapted_VGG16.compile(optimizer =Ad, loss = 'categorical_crossentropy',metrics = ['accuracy'] )\n",
    "\n",
    "adapted_VGG16.fit(X_train,y_train,epochs = 10, batch_size = 19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Experimental Network\n",
    "this network is based on VGG16 but has been simplified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_network_1( input_shape,weights_path = None):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=input_shape))\n",
    "    \n",
    "    model.add(Convolution2D(32,(3,3),activation ='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(32,(3,3),activation ='relu'))\n",
    "    #model.add(MaxPooling2D((2,2),strides = (2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(64,(3,3),activation ='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64,(3,3),activation ='relu'))\n",
    "    model.add(MaxPooling2D((2,2),strides = (2,2)))\n",
    "    \n",
    "    model.add(Convolution2D(128,(3,3),activation ='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128,(3,3),activation ='relu'))\n",
    "    model.add(MaxPooling2D((2,2),strides = (2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu',name=\"dense1\"))\n",
    "    model.add(Dense(1024, activation='relu',name=\"dense2\"))\n",
    "    model.add(Dense(120, activation= 'softmax',name=\"dense3\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the network using an rmsprop optimizer\n",
    "model = conv_network_1(input_shape = (image_size,image_size,3))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'] )\n",
    "model.fit(X_train,y_train,epochs = 10, batch_size = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for layer in model.layers:\n",
    "#    print(layer.get_output_at(0).get_shape().as_list())\n",
    "#model.fit(X,y,epochs = 10, batch_size = 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_network_2(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((1,1),input_shape=input_shape)(X_input)\n",
    "    \n",
    "    X = Convolution2D(32,(5,5),activation ='relu',name='conv1a')(X)\n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Convolution2D(32,(5,5),activation ='relu',name='conv1b')(X)\n",
    "    X = MaxPooling2D((2,2),strides = (2,2),name = 'pool1a')(X)\n",
    "    \n",
    "    X = Convolution2D(64,(3,3),activation ='relu',name='conv2a')(X)\n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Convolution2D(64,(3,3),activation ='relu',name='conv2b')(X)\n",
    "    X = MaxPooling2D((2,2),strides = (2,2),name = 'pool2a')(X)\n",
    "    \n",
    "    X = Convolution2D(128,(3,3),activation ='relu',name='conv3a')(X)\n",
    "    X = ZeroPadding2D((1,1))(X)\n",
    "    X = Convolution2D(128,(3,3),activation ='relu',name='conv3b')(X)\n",
    "    X = MaxPooling2D((2,2),strides = (2,2),name = 'pool3a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(120, activation='relu',name=\"dense1\")(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name = 'convnet2')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model2 = conv_network_2(X.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model2.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model2.fit(X,y,epochs = 10, batch_size = 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
